{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b765f016-1074-42b6-a132-6d3e4efaab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed489c-a570-43e3-8610-3a3ffa70d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_dir = \"frames/LPBF_Cyl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5c84f-6678-4821-970b-37831f58d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "checkpoint = \"../checkpoints/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "predictor = build_sam2_video_predictor(model_cfg, checkpoint)\n",
    "\n",
    "# predictor.reset_state(inference_state)\n",
    "inference_state = predictor.init_state(video_path=frame_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42005b-5072-461d-91e4-41d3c750f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame_names = [\n",
    "    p for p in os.listdir(frame_dir)\n",
    "    if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9195cb-73a4-4733-984e-d400643a70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 1153\n",
    "\n",
    "img_path = os.path.join(frame_dir, frame_names[frame_idx])\n",
    "img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pointlist = []\n",
    "\n",
    "def onclick(event):\n",
    "    if event.xdata is not None and event.ydata is not None:\n",
    "        # Koordinaten in int runden, falls gewünscht:\n",
    "        x = int(event.xdata)\n",
    "        y = int(event.ydata)\n",
    "        points.append((x, y))\n",
    "        print(\"Point:\", (x, y))\n",
    "\n",
    "# wichtig für JupyterLab\n",
    "%matplotlib widget\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(f\"Frame {frame_idx}\")\n",
    "ax.imshow(img)\n",
    "\n",
    "# Event registrieren\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52f1fe-8540-446f-80bf-099936b60227",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e325167-4d10-4411-b516-5342d171be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6f42d-7ad2-4fc6-9dff-9f4c4bf66371",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3865ea6-6de2-4384-9b0d-34a2a5232b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deactivate canvas frontend for normal plots\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcc758-f4c8-4a2b-ae7a-77f0ba9d34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_obj_ids, out_mask_logits = annotate_frame_interactive(\n",
    "    \"cylinder\",\n",
    "    0,\n",
    "    np.array([\n",
    "        (59, 244), (77, 159), (135, 89), (215, 48), (303, 49), (381, 88), (433, 158), (455, 242), (433, 330), (381, 396), (301, 437), (214, 438), (137, 399), (77, 326),(51, 245), (458, 250),\n",
    "        (71, 204), (105, 125), (176, 65), (261, 50), (344, 63), (412, 127), (441, 199), (444, 289), (406, 362), (348, 414), (259, 428), (167, 408), (110, 375), (65, 289)\n",
    "    ],\n",
    "    dtype=np.float32),\n",
    "    np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0 ,0 ,0], dtype=np.int32), \n",
    "    frame_index=0,\n",
    "    color=\"green\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f501ee-e7e1-42d4-91c9-8c303c7d8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_obj_ids, out_mask_logits = annotate_frame_interactive(\n",
    "    \"cylinder\",\n",
    "    0,\n",
    "    np.array([\n",
    "      (60, 255), (60, 233), (79, 169), (86, 150), (126, 97), (143, 83), (206, 57), (226, 50), (289, 55), (311, 59), (371, 87), (389, 95), (431, 149), (443, 170),\n",
    "      (455, 232), (455, 254), (440, 322), (429, 339), (387, 390), (372, 401), (311, 433), (292, 438), (224, 434), (204, 432), (147, 402), (126, 392), (84, 340), (76, 320),\n",
    "        (68, 203), (102, 123), (169, 74), (253, 50), (340, 68), (409, 119), (444, 205), (444, 290), (406, 366), (336, 423), (258, 437), (175, 427), (100, 372), (64, 288),\n",
    "        (155, 13), (300, 56), (379, 94), (432, 162), (428, 210), (456, 245), (437, 332), (85, 329), (374, 392),\n",
    "       (444, 254), (445, 236), (381, 106), (365, 93), (306, 68), (288, 65),\n",
    "        (71, 245), (88, 163), (138, 95), (217, 58), (300, 56), (379, 93), (441, 156), (459, 243), (430, 327), (383, 402), (298, 426), (215, 435), (137, 397), (86, 327),\n",
    "        (56, 245), (76, 159), (129, 85), (302, 45), (443, 245), (216, 425), (142, 389), (75, 331), (383, 87), (425, 325), (216, 60)\n",
    "     \n",
    "    ],\n",
    "    dtype=np.float32),\n",
    "    np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "              1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, \n",
    "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "              0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "             1, 1, 1, 1, 1, 1,\n",
    "               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         \n",
    "            \n",
    "    ], dtype=np.int32), \n",
    "    frame_index=40,\n",
    "    color=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426a38e-aed2-4147-a060-9700f0c32507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_obj_ids, out_mask_logits = annotate_frame_interactive(\n",
    "    \"cylinder\",\n",
    "    0,\n",
    "    np.array([(149, 242), (225, 257),\n",
    "              (60, 200), (76, 203), (105, 120), (174, 70), (257, 47), (335, 77), (345, 62), (414, 119), (398, 131), (453, 201), (457, 287), (441, 287), (409, 368), (343, 421), (256, 438), (171, 422), (180, 407), (106, 367), (66, 284),\n",
    "              (83, 156), (142, 89), (222, 49), (299, 54), (370, 92), (429, 160), (444, 243), (434, 333), (370, 400), (297, 427), (210, 431), (139, 400), (72, 323), (58, 239)\n",
    "    ],\n",
    "    dtype=np.float32),\n",
    "    np.array([0, 0,\n",
    "              1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, \n",
    "               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "    ], dtype=np.int32), \n",
    "    frame_index=140,\n",
    "    color=\"green\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273cf55-f946-40cd-b21e-e2a36ee4aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_obj_ids, out_mask_logits = annotate_frame_interactive(\n",
    "    \"cylinder\",\n",
    "    0,\n",
    "    np.array([(470, 460), (449, 291), (449, 202), (412, 122),\n",
    "              (359, 69), (351, 83), (407, 105), (394, 121), (428, 129), (412, 141), (453, 186), (435, 192), (460, 215), (443, 217), (459, 276), (446, 302), (414, 353), (425, 359), (403, 380), (355, 415),\n",
    "             (331, 427), (272, 439), (244, 437), (243, 448), (184, 435), (190, 418), (158, 420), (166, 406), (109, 384), (119, 373), (90, 360), (103, 351), (62, 306), (78, 300), (56, 276), (72, 276),\n",
    "              (60, 215), (66, 186), (77, 190), (92, 132), (114, 113), (160, 71), (165, 82), (184, 53), (190, 76), (241, 38), (246, 62), (274, 41), (271, 62), (333, 54), (327, 75),\n",
    "              (454, 242), (434, 158), (372, 92), (302, 57), (214, 58), (128, 99), (80, 162), (64, 244), (80, 335), (137, 395), (218, 434), (296, 432), (377, 400), (440, 323)\n",
    "    ],\n",
    "    dtype=np.float32),\n",
    "    np.array([0, 0, 0, 0,\n",
    "              1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "              1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "              1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    ], dtype=np.int32), \n",
    "    frame_index=205,\n",
    "    color=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ae774-9da7-4879-98e8-d12f5f11036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_obj_ids, out_mask_logits = annotate_frame_interactive(\n",
    "    \"cylinder\",\n",
    "    0,\n",
    "    np.array([(450, 245), (449, 201), (450, 290), (412, 121)\n",
    "    ],\n",
    "    dtype=np.float32),\n",
    "    np.array([0, 0, 0, 0\n",
    "    ], dtype=np.int32), \n",
    "    frame_index=837,\n",
    "    color=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe864e1a-5179-4346-aaa5-5de3efc76730",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_obj_ids, out_mask_logits = annotate_frame_interactive(\n",
    "    \"cylinder\",\n",
    "    0,\n",
    "    np.array([(250, 250), \n",
    "              (257, 47), (342, 69), (410, 123), (450, 201), (446, 285), (409, 363), (342, 417), (256, 437), (174, 421), (104, 367), (71, 287), (69, 202), (105, 122), (172, 65)\n",
    "    ],\n",
    "    dtype=np.float32),\n",
    "    np.array([0, \n",
    "               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    ], dtype=np.int32), \n",
    "    frame_index=1153,\n",
    "    color=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457f2d6-8b3e-42f7-acf8-3f227c1fe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_segments = {}\n",
    "for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "    video_segments[out_frame_idx] = {\n",
    "        out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "        for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "\n",
    "with open(\"pickle_files/LPBF_Karsten25_CYL_New4.pkl\", \"wb\") as f:\n",
    "    pickle.dump(video_segments, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22eed0-a3e3-4be1-a63a-34bab72ed565",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef6e2d-09bf-493f-8a19-e9bcff66fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle_files/LPBF_Karsten25_CYL_New3.pkl\", \"rb\") as f:\n",
    "    video_segments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c5bc5-56f3-4bf6-ba50-367ee899ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vis_frame_stride = 100\n",
    "plt.close(\"all\")\n",
    "for out_frame_idx in range(0, len(frame_names), vis_frame_stride):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(f\"frame {out_frame_idx}\")\n",
    "    plt.imshow(Image.open(os.path.join(frame_dir, frame_names[out_frame_idx])))\n",
    "    for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "        show_mask(out_mask, plt.gca(), obj_id=out_obj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ce5c6-fd70-409f-ab11-f0658586d42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17eb102-a27b-4426-b13f-56138460f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feste Farben pro Klasse (BGR für OpenCV!)\n",
    "CLASS_COLORS = {\n",
    "    0: (0,   0, 255),   # Rot\n",
    "    1: (0, 255,   0),   # Grün\n",
    "    2: (255, 0,   0),   # Blau\n",
    "    3: (0, 255, 255),   # Gelb\n",
    "    4: (255, 0, 255),   # Magenta (falls weitere Klassen existieren)\n",
    "    5: (255,255,  0),   # Cyan\n",
    "}\n",
    "\n",
    "for out_frame_idx in tqdm(range(len(frame_names)), desc=\"Processing frames\"):\n",
    "\n",
    "    sample_mask = next(iter(video_segments[out_frame_idx].values()))\n",
    "    h, w = sample_mask.shape[-2:]\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    # Für alle Segmente dieses Frames\n",
    "    for cls_id, out_mask in video_segments[out_frame_idx].items():\n",
    "\n",
    "        if cls_id not in CLASS_COLORS:\n",
    "            continue  # ohne Farbdefinition überspringen\n",
    "        \n",
    "        mask = out_mask.reshape(h, w)\n",
    "        b, g, r = CLASS_COLORS[cls_id]\n",
    "        color_mask[mask] = (b, g, r)\n",
    "   \n",
    "    cv2.imwrite(\n",
    "        f\"frames/LPBF_CYL_MASK_NEW4/{str(out_frame_idx).zfill(4)}.tif\",\n",
    "        color_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138fce4-5165-4988-b6ff-2db85ac60af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only segment xxx\n",
    "for out_frame_idx in tqdm(range(len(frame_names)), desc=\"Processing frames\"):\n",
    "    \n",
    "    # Segment 0 aus dem aktuellen Frame holen\n",
    "    out_mask = video_segments[out_frame_idx][0]   # nur Klasse 0\n",
    "\n",
    "    h, w = out_mask.shape[-2:]\n",
    "\n",
    "    # Boolean -> uint8 Maske (0 / 255)\n",
    "    mask_image = (out_mask.reshape(h, w) * 255).astype(np.uint8)\n",
    "\n",
    "    # Als TIFF speichern\n",
    "    cv2.imwrite(\n",
    "        f\"frames/LPBF_Karsten25_mask25252/{str(out_frame_idx).zfill(4)}.tif\",\n",
    "        mask_image\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f58bb-63a8-4bcc-851e-88f579b5be55",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178e9f6-3d9d-4981-8427-a5ba48e0dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame(name, object_id, points, labels, frame_index=0, show_figure=True, color=None):\n",
    "    _, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
    "        inference_state=inference_state,\n",
    "        frame_idx=frame_index,\n",
    "        obj_id=object_id,\n",
    "        points=points,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    if show_figure:\n",
    "        plt.figure(figsize=(9, 6))\n",
    "        plt.title(f\"frame {frame_index}\")\n",
    "        plt.imshow(Image.open(os.path.join(frame_dir, frame_names[frame_index])))\n",
    "        show_points(points, labels, plt.gca())\n",
    "        show_mask((out_mask_logits[object_id] > 0.0).cpu().numpy(), plt.gca(), obj_id=out_obj_ids[object_id], color=color)\n",
    "\n",
    "    return out_obj_ids, out_mask_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2fdc7e-904b-4d34-9bb7-181086d4bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame_interactive(name, object_id, points, labels, frame_index=0, color=None):\n",
    "\n",
    "    global pointlist\n",
    "    pointlist = []\n",
    "    \n",
    "    #ursprüngliches SAM + Zeichnen ----\n",
    "    out_obj_ids, out_mask_logits = annotate_frame(\n",
    "        name=name,\n",
    "        object_id=object_id,\n",
    "        points=points,\n",
    "        labels=labels,\n",
    "        frame_index=frame_index,\n",
    "        show_figure=True,\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "    # Das Fenster, das annotate_frame gerade erstellt hat\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    def onclick(event):\n",
    "        if event.xdata is None or event.ydata is None:\n",
    "            return\n",
    "\n",
    "        x = int(event.xdata)\n",
    "        y = int(event.ydata)\n",
    "        pointlist.append((x, y))\n",
    "\n",
    "        # direkt sichtbar machen\n",
    "        ax.scatter([x], [y], color='yellow', s=10, edgecolor='black')\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.show()\n",
    "    return out_obj_ids, out_mask_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187cac4f-4969-45c3-a988-d2e1b19c3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1243/1243 [00:40<00:00, 30.96it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(raw_dir, frame_dir):\n",
    "    sorted_files = sorted(os.listdir(raw_dir), key=lambda f: int(f.split(\"_\")[1]))\n",
    "    len(sorted_files)\n",
    "    count = 0;\n",
    "    for f in sorted_files:\n",
    "        img = cv2.imread(os.path.join(raw_dir, f))\n",
    "        img_cropped = img[160:1400,:1400]\n",
    "        #(218, 241), (702, 712)\n",
    "        #img_cropped = img[241:712,218:702]\n",
    "        cv2.imwrite(os.path.join(frame_dir, f\"{count:04d}.jpg\"), img_cropped)\n",
    "        count += 1\n",
    "\n",
    "def preprocess1(raw_dir, frame_dir):\n",
    "    files = [\n",
    "        f for f in os.listdir(raw_dir)\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "    ]\n",
    "\n",
    "    def sort_key(f):\n",
    "        parts = f.split(\"_\")\n",
    "        if len(parts) > 1 and parts[1].isdigit():\n",
    "            return int(parts[1])\n",
    "        else:\n",
    "            return -1   # Dateien ohne gültigen Index ganz nach vorne / hinten\n",
    "\n",
    "    sorted_files = sorted(files, key=sort_key)\n",
    "\n",
    "    os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "    for count, f in enumerate(sorted_files):\n",
    "        img = cv2.imread(os.path.join(raw_dir, f))\n",
    "        if img is None:\n",
    "            print(f\"Warnung: konnte {f} nicht lesen\")\n",
    "            continue\n",
    "\n",
    "        img_cropped = img[160:1400, :1400]\n",
    "        cv2.imwrite(os.path.join(frame_dir, f\"{count:04d}.jpg\"), img_cropped)\n",
    "\n",
    "\n",
    "def crop(raw_dir, out_dir):\n",
    "    sorted_files = [f for f in sorted(os.listdir(raw_dir))\n",
    "                    if f.lower().endswith((\".jpg\", \".png\", \".tif\", \".jpeg\"))]\n",
    "\n",
    "    count = 0;\n",
    "    for count, f in enumerate(tqdm(sorted_files, desc=\"Cropping\")):\n",
    "        img = cv2.imread(os.path.join(raw_dir, f))\n",
    "        #(218, 241), (702, 712) #old \n",
    "        #img_cropped = img[241:712,218:702] #cylinder\n",
    "        img_cropped = img[241:712,218:702] #tree\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(os.path.join(out_dir, f\"{count:04d}.jpg\"), img_cropped)\n",
    "        count += 1\n",
    "\n",
    "     \n",
    "raw_dir = r\"N:\\Projekte\\ZIM_Amaize-Q\\14_Karsten_Analyse\\20251203_M400_AlSi10Mg_Baum_Wand_Lattice\\EOT\\Bilder\\Crop_Gray\"\n",
    "frame_dir = r\"N:\\Projekte\\ZIM_Amaize-Q\\14_Karsten_Analyse\\20251203_M400_AlSi10Mg_Baum_Wand_Lattice\\EOT\\Bilder\\Crop_Gray_Zyl\"\n",
    "\n",
    "#preprocess(\"raw/01\", frame_dir)\n",
    "#preprocess1(raw_dir, frame_dir)\n",
    "crop(raw_dir, frame_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357ef8d-c7db-4b29-820d-df4f862ee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, obj_id=None, color=None):\n",
    "    color_map = {\n",
    "        \"red\": np.concatenate([np.array([1.0, 0.0, 0.0]), np.array([0.6])], axis=0),\n",
    "        \"green\": np.concatenate([np.array([0.0, 1.0, 0.0]), np.array([0.6])], axis=0),\n",
    "        \"blue\": np.concatenate([np.array([0.0, 0.0, 1.0]), np.array([0.6])], axis=0),\n",
    "    }\n",
    "    \n",
    "    if color is None:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = color_map[color]\n",
    "        \n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=50):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8227d4f-456e-474e-83ca-26f9aa19dab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2880315-aecd-4e9f-8e03-53c17e2cde1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
